---
title: "The pathology of statistics"
author: "Ho-Ryun Chung"
description: ""
date: "2024-11-29"
bibliography: pathologyStatistics.bib
categories:
  - general
  - statistics
---

Statisticians think along the lines of a distribution that generates data. The hope is that such a distribution is of a simple form, e.g. the normal distribution. The only problem: this remains a hope. Why? Because the you cannot possibly ascertain that the data is generated by any distribution. There are infinitely many distributions that could have generated the data such that even if you guessed correctly, you would not even know it. The quest for the distribution that generated the data is ill-defined.

Your inability to identify the distribution that generated the data has immediate repercussions on the validity of statistical inferences. These are based on statistical models that rely on assumptions on the distribution that generated the data. As outlined above, you have no way to ascertain that the data was generated by the conjectured distribution. Since the statistical model may be wrong because you do not know whether your assumptions on the data generation is correct, also the validity of your inferences becomes uncertain.

> All models are wrong, some are useful. - George Box

This common aphorism attributed to George Box, a British statistician, summarizes the basic pathology of statistics as it is practiced today. Usefulness is the only criterion that measures the merit of statistical models. However, how can you measure usefulness if you are charting the unknown? Well, myriads of studies showed the usefulness of established statistical models. The crux is: they are useful until they are not and you do not know when they are not.

## The useful $t$-test

The two-sample $t$-test is one of the most widely used statistical hypothesis tests. It is used to statistically ascertain whether the mean value of a metric attribute is different in two groups. Your working hypothesis could be that "the *conditional* mean of $Y$ in the population is different in group $\text{A}$ versus group $\text{B}$". To test this hypothesis you gather data, i.e. you measure/observe the values of attribute $Y$ from individuals drawn from the "population" (Grundgesamtheit) and determine their group membership. In most cases you will not be able to assay all individuals of a population but only a sample (Stichprobe) of it such that you are uncertain whether the conditional sample means of $Y$ of group $\text{A}$ versus $\text{B}$ correspond to the population counterparts (if you sampled all the population then this uncertainty would be gone). In most cases, the conditional sample means will differ (even if they were the same in the population).

Here comes the first twist. Instead of testing your working hypothesis, you invent a new hypothesis, the **null hypothesis**, which corresponds to the deductive negation of your working hypothesis: the conditional means of attribute $Y$ in the population are the same in group $\text{A}$ and group $\text{B}$. It is the null hypothesis, which you want to contradict (with data). From the rejection of the null hypothesis you want to infer the truth of your working hypothesis, now coined **alternative hypothesis**: the conditional means of attribute $Y$ in the population are different in group $\text{A}$ versus group $\text{B}$.

Here comes the second twist. What exactly is your null hypothesis? Colloquially, you think along the lines:

$$
\mu_\text{A} = \mu_\text{B},
$$

where $\mu_\text{A}$ is the conditional mean of $Y$ in the subpopulation of group $\text{A}$, and $\mu_\text{B}$ is the conditional mean of $Y$ in the subpopulation of group $\text{B}$. The problem with this colloquial statement: you conjecture that the conditional means are the same but you do not know their common value.

If you knew the common value $\mu_0$ of $\mu_\text{A}$ (and $\mu_\text{B}$), you obtain a mathematical description of your hypothesis:

$$
\begin{aligned}
\mu_\text{A} &= \mu_0 \\
\mu_\text{B} &= \mu_0
\end{aligned}.
$$

However, if you do not know the common value $\mu_0$ you are left with

$$
\mu_\text{A} - \mu_\text{B} = 0,
$$

which leaves the value of $\mu_\text{A}$ (and $\mu_\text{B}$) unspecified but states the fact that they are the same.
