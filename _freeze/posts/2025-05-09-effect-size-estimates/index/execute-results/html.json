{
  "hash": "0d0975672f210b8c5135f950a3184811",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Effect size estimates\"\nauthor: \"Ho Ryun Chung\"\ndescription: \"\"\ndate: \"2025-05-09\"\ncategories: []\n---\n\n\n**Problem**: Comparison between two treatments A and B, which one is better?\n\nWe compare the success rate of two treatments for kidney stones. This is the data\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|      |A                 |B                 |                  |\n|:-----|:-----------------|:-----------------|:-----------------|\n|small |**93%** (81/87)   |87% (234/270)     |**88%** (315/357) |\n|large |**73%** (192/263) |69% (55/80)       |72% (247/343)     |\n|both  |78% (275/350)     |**83%** (289/350) |                  |\n\n\n:::\n:::\n\nTreatment A is better (higher success rate) when used on small stones as well as on large stones, yet treatment B appears to be better considering both sizes together. This paradoxical result is called \"Simpson's paradox\".\n\nThe effect size estimate of treatment A versus treatment B in the combined analysis is confounded by the tendencies of doctors to send cases with large stones to treatment A and cases with small stones to treatment B, while the treatment of small stones (irrespective of the treatment type) is more successfull than the treatment of large stones.\n\nIn this sense the stone size acts as confounder for the effect size estimate of treatment B versus A. First, we try a generalized linear model to \"remove\" the confounding effect of the stone size on the treatment effect.\n\nFirst, we produce a data table `dt`\n\n::: {.cell}\n\n```{.r .cell-code}\ndt <- data.frame(as.table(data))\ndt <- lapply(\n  seq_len(nrow(dt)),\n  function(i){\n    dt[rep(i, dt$Freq[i]), c(\"stoneSize\", \"treatment\", \"success\")]\n  }\n)\ndt <- do.call(rbind, dt)\n```\n:::\n\nThe data table `dt` now has 700 rows, each one representing a patient, and records in the columns the stone size, the type of treatment, and treatment success. We use this data to fit a generalized linear model of the binomial family with identity link \n\n::: {.cell}\n\n```{.r .cell-code}\nlinearGLM <- glm(\n  formula = success ~ stoneSize + treatment, \n  family = binomial(link = \"identity\"), \n  data = dt\n)\nsummary(linearGLM)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = success ~ stoneSize + treatment, family = binomial(link = \"identity\"), \n    data = dt)\n\nCoefficients:\n               Estimate Std. Error z value Pr(>|z|)    \n(Intercept)     0.92743    0.02541  36.493  < 2e-16 ***\nstoneSizelarge -0.19393    0.03202  -6.056  1.4e-09 ***\ntreatmentB     -0.05879    0.02984  -1.970   0.0488 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 694.98  on 699  degrees of freedom\nResidual deviance: 661.96  on 697  degrees of freedom\nAIC: 667.96\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n:::\n\nThis analysis deconfounds the effect size estimate for the treatment from the stone size at the level of the main effects. Treatment B reduces the success rate by 5.9% consistent with the analysis stratified by stone size.\n\nHowever, given that the data shows a pronounced dependency between the stone size and the treatment it may be more realistic to also include the interaction term between stone size and treatment leading to a saturated model \n\n::: {.cell}\n\n```{.r .cell-code}\nsaturatedGLM <- glm(\n  formula = success ~ stoneSize + treatment + stoneSize:treatment, \n  family = binomial(link = \"identity\"), \n  data = dt\n)\nsummary(saturatedGLM)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = success ~ stoneSize + treatment + stoneSize:treatment, \n    family = binomial(link = \"identity\"), data = dt)\n\nCoefficients:\n                          Estimate Std. Error z value Pr(>|z|)    \n(Intercept)                0.93103    0.02717  34.271  < 2e-16 ***\nstoneSizelarge            -0.20100    0.03857  -5.212 1.87e-07 ***\ntreatmentB                -0.06437    0.03415  -1.885   0.0594 .  \nstoneSizelarge:treatmentB  0.02183    0.06783   0.322   0.7476    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 694.98  on 699  degrees of freedom\nResidual deviance: 661.86  on 696  degrees of freedom\nAIC: 669.86\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n:::\n\nThis more detailed analysis reveals that treatment B reduces the success rate by 6.4%, i.e. the (absolute) effect size estimate increases. However, while in the pure linear GLM the reduction of the treatment success was statistical significant at a significance level of 5% (p-value 0.049; Wald-test?), the more detailed analysis was not (p-value 0.059; Wald-test?). In both analyses the main stone size effect -- a reduction of 19.4% (linear) or 6.4% (saturated) -- remains significant.\n\n**Empirical likelihood ratio test**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ELTseq)\nlibrary(S4Vectors)\nm <- as.numeric(prop.table(data, margin = c(1,2))[,,\"yes\"])\nx <- data.frame(as.table(data[,,\"yes\"]))\nfullDesignMatrix <- model.matrix(~ stoneSize*treatment, data = x)\n(res <- solve(t(fullDesignMatrix) %*% fullDesignMatrix, t(fullDesignMatrix) %*% m))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                 [,1]\n(Intercept)                0.93103448\nstoneSizelarge            -0.20099646\ntreatmentB                -0.06436782\nstoneSizelarge:treatmentB  0.02182979\n```\n\n\n:::\n\n```{.r .cell-code}\nall.equal(res[ ,1], saturatedGLM$coefficients)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nentities <- data.frame(as.table(data))\nentities$empirical = entities$Freq / sum(entities$Freq)\n## group matching\ngroups <- subset(x, select = c(\"stoneSize\", \"treatment\"))\nentitiesToGroups <- match(DataFrame(subset(entities, select = c(\"stoneSize\", \"treatment\"))), DataFrame(groups))\ngroupFreq <- tapply(\n  entities$empirical, \n  entitiesToGroups, \n  sum\n)\nconstraints <- solve(fullDesignMatrix %*% t(fullDesignMatrix), fullDesignMatrix %*% c(0,0,1,0))\n\nF <- rbind(\n  constraints[entitiesToGroups,1] * ifelse(entities$success == \"yes\", 1, 0) / groupFreq[entitiesToGroups],\n  entitiesToGroups == 1,\n  entitiesToGroups == 2,\n  entitiesToGroups == 3,\n  entitiesToGroups == 4\n)\n\npH <- iProjector(F, eta = c(0, groupFreq), v = entities$empirical)\niDiv <- iDivergence(entities$empirical, pH$p)\npchisq(iDiv * 700 * 2, df = 1, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0857172\n```\n\n\n:::\n\n```{.r .cell-code}\ngroupMeans <- tapply((entities$success == \"yes\") * pH$p, entitiesToGroups, sum) / groupFreq\n(res2 = solve(t(fullDesignMatrix) %*% fullDesignMatrix, t(fullDesignMatrix) %*% groupMeans))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                 [,1]\n(Intercept)                0.88593929\nstoneSizelarge            -0.15590127\ntreatmentB                 0.00000000\nstoneSizelarge:treatmentB -0.04253802\n```\n\n\n:::\n\n```{.r .cell-code}\nall.equal(res2[-4,1], linearGLM$coefficients)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Mean relative difference: 0.1327494\"\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconstraints <- solve(fullDesignMatrix %*% t(fullDesignMatrix), fullDesignMatrix %*% c(0,0,0,1))\n\nF <- rbind(\n  constraints[entitiesToGroups,1] * ifelse(entities$success == \"yes\", 1, 0) / groupFreq[entitiesToGroups],\n  entitiesToGroups == 1,\n  entitiesToGroups == 2,\n  entitiesToGroups == 3,\n  entitiesToGroups == 4\n)\n\npH <- iProjector(F, eta = c(0, groupFreq), v = entities$empirical)\niDiv <- iDivergence(entities$empirical, pH$p)\npchisq(iDiv * 700 * 2, df = 1, lower.tail = FALSE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.7490086\n```\n\n\n:::\n\n```{.r .cell-code}\ngroupMeans <- tapply((entities$success == \"yes\") * pH$p, entitiesToGroups, sum) / groupFreq\n(res2 = solve(t(fullDesignMatrix) %*% fullDesignMatrix, t(fullDesignMatrix) %*% groupMeans))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                 [,1]\n(Intercept)                0.92748157\nstoneSizelarge            -0.19393383\ntreatmentB                -0.05881492\nstoneSizelarge:treatmentB  0.00000000\n```\n\n\n:::\n:::\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nbeta <- c(rnorm(1, sd = 5), rnorm(3), rnorm(3, sd = 0.5), rnorm(1, sd = 0.25))\n#beta[5:8] = 0\nx = cbind(expand.grid(x1 = c(0,1), x2 = c(0,1), x3 = c(0,1)))\ndm2 <- model.matrix(~x1*x2*x3, data = x)\n\nk = 100\nnboot = 1000\nm = dm2 %*% beta\nxx <- x[rep(1:8, each = k), ]\ndm <- model.matrix(~ x1 * x2 * x3, data = xx)\n\ntest <- lapply(\n  seq_len(nboot),\n  function(i){\n    y = as.numeric(\n      sapply(\n        m,\n        function(mean){\n          mean + rnorm(k, sd = 1)\n        }\n      )\n    )\n    mm <- tapply(y, rep(1:8, each = k), mean)\n    list(\n      betaFull = solve(t(dm2) %*% dm2, t(dm2) %*% mm)[,1],\n    \n      betaLinear = lm(y ~ x1 + x2 + x3, data = xx)$coef\n    )\n    \n    \n  }\n)\n\n\nbFull = do.call(cbind, lapply(test, function(x) x$betaFull))\nbLinear = do.call(cbind, lapply(test, function(x) x$betaLinear))\n\n## obviously this does not work\nplot(as.numeric(bFull), rep(1:8, nboot), xlim = range(bFull, bLinear), xlab = \"beta\", yaxt = \"n\", frame = FALSE, ylab = \"coefficients\")\naxis(2, at = 1:8, labels = rownames(bFull))\npoints(as.numeric(bLinear), rep(1:4 + 0.3, nboot), col = 2)\nsegments(beta, 1:8 - 0.5, beta, 1:8 + 0.5, col = \"orange\", lwd = 3)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}